# Adversarial samples: Attack and defend

Research about adversarial samples recently is a hot topic in Machine Learning. In this repository, i just want to introduce some methods for generating adversarial samples and how to defend against them.

## Note: There's still many other interesting methods, i will update later in the future.

## Installation

All methods here are implemented in Pytorch. I think there's no need to concern about the version conflict here. My code is simple and don't need special packages. All you need to do is install Pytorch (and other basic packages like numpy, matplotlib,...).

## The README in each folder is little bit messy!!!. I will reorganize them.

**Update**:

- Notebook can be found [here](https://colab.research.google.com/drive/16mpKLYmeZTrbAsDsX_k8SWYIvH0aZaD2?usp=sharing).